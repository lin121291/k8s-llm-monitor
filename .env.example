# LLM Configuration
LLM_MODEL=llama-3.2-3b
MAX_TOKENS=2048
TEMPERATURE=0.1

# Scaling Configuration
PREDICTION_WINDOW=30m
SCALE_THRESHOLD=0.8
MIN_REPLICAS=2
MAX_REPLICAS=20

# Monitoring URLs
PROMETHEUS_URL=http://prometheus:9090
GRAFANA_URL=http://grafana:3000

# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS=kafka:9092

# Redis Configuration
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0

# GCP Configuration
GCP_PROJECT_ID=your-gcp-project-id
DOCKER_REGISTRY=gcr.io/your-gcp-project-id

# Security (for Docker Compose)
GRAFANA_ADMIN_PASSWORD=your-secure-password-here

# Application Configuration
CONFIG_PATH=/app/config/monitor.yaml
LOG_LEVEL=INFO

# Kubernetes Configuration (if running outside cluster)
KUBECONFIG=/path/to/kubeconfig