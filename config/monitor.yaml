project:
  name: "AI-log"
  gcp_project_id: "your-gcp-project-id"  # Replace with your GCP project ID
  docker_registry: "gcr.io/your-gcp-project-id"  # Replace with your registry
  namespace: "ai-monitor"

llm:
  provider_type: "auto"
  model: "llama3.2:3b"
  max_tokens: 2048
  temperature: 0.1
  ollama_url: "http://localhost:11434"
  device: "auto"

scaling:
  prediction_window: "30m"
  scale_threshold: 0.8
  min_replicas: 2
  max_replicas: 20
  cooldown_period: "5m"

monitoring:
  prometheus_url: "http://prometheus:9090"
  grafana_url: "http://grafana:3000"
  log_retention: "7d"

kafka:
  bootstrap_servers: "kafka:9092"
  topics:
    logs: "service-logs"
    metrics: "service-metrics"
    alerts: "service-alerts"

redis:
  host: "redis"
  port: 6379
  db: 0

logging:
  level: "INFO"
  format: "json"
  handlers:
    - console
    - file

security:
  enable_tls: true
  cert_path: "/etc/ssl/certs"
  key_path: "/etc/ssl/private"